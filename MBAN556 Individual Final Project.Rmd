---
title: "MBAN556 Individual Final Project"
author: "Meiji Supakamolsenee"
date: "2024-12-10"
output: 
  html_document:
    toc: true
    toc_float: true
    number_sections: true
---
## Introduction
Michigan Medicine is committed to advancing cancer detection methods through the innovative use of patient health data. This analysis aims to explore the potential of unsupervised learning techniques—such as Principal Component Analysis (PCA), K-Nearest Neighbors (KNN), and clustering models—to enhance cancer diagnosis. The primary goal is to uncover patterns or anomalies in the data that align with cancer presence, **minimizing false negatives while maintaining high sensitivity and precision**. Success will be evaluated based on the sensitivity of the models in correctly identifying cancer cases and the interpretability of the findings for practical implementation in a clinical setting.

The outcomes of this analysis will guide Michigan Medicine in integrating data-driven insights into cancer diagnostics, enabling early detection and reducing mortality rates. By focusing on insights, this report provides actionable recommendations for incorporating unsupervised learning into medical decision-making processes.

## Methodology Overview
To achieve the objectives, we applied unsupervised learning methods to analyze the data. Key steps include:

Data Preprocessing: Cleaning and standardizing data.
Clustering Analysis: Using methods such as k-means and hierarchical clustering to identify patterns.
Outlier Detection: Applying advanced techniques to isolate potential high-risk cases.
Performance Metrics: Sensitivity and precision were prioritized, with a specific focus on minimizing false negatives.


## Install important Packages
```{r}
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(cluster))
suppressPackageStartupMessages(library(FNN))
suppressPackageStartupMessages(library(caret))
suppressPackageStartupMessages(library(factoextra))
suppressPackageStartupMessages(library(solitude))
suppressPackageStartupMessages(library(knitr))
suppressPackageStartupMessages(library(dbscan))
suppressPackageStartupMessages(library(cowplot))
suppressPackageStartupMessages(library(caret))
```

## Data Cleaning and Preprocessing
### Import and explore the dataset
```{r}
wbc.raw <- read.csv("wbc.csv")
summary(wbc.raw)
str(wbc.raw)
sum(is.na(wbc.raw)) # Verified no missing values existed in the dataset
```

### Scale the data for consistency
```{r}
# Scaled all numerical features to standardize the data for PCA and clustering and retained only relevant features
wbc.data <- as.data.frame(scale(wbc.raw[ , -ncol(wbc.raw)])) # scale and remove y (outcome) column
str(wbc.data)
summary(wbc.data)
```

### Insights from Data Preparation
The dataset was loaded and carefully examined for missing values, inconsistencies, and the need for scaling. No missing values were detected, and the data was normalized to ensure comparability across features. This step was critical for the effective performance of PCA, KNN, and clustering models.

## (Q1) Principal Component Analysis (PCA)
```{r}
# Perform PCA
pca.result <- prcomp(wbc.data, scale. = FALSE)
summary(pca.result)
```

### Interpretation of PCA
PC1 captures 37.78% of the variance, with each subsequent component contributing progressively less. Principal components are designed to maximize the variance captured, with each adding unique and meaningful information. Based on the pca result, to meet the goal of **capturing 97% of the total variance, the first 12 principal components are required**. Utilizing these components significantly reduces the dataset's dimensionality while retaining most of its critical information. This approach ensures the model effectively represents the underlying patterns in the data, enhancing its accuracy and interpretability.

### Dimensionality Reduction to capture 97% of the variance
```{r}
wbc.pca <- as.data.frame(pca.result$x[,1:12]) #selecting 12 PCA columns
summary(wbc.pca)
str(wbc.pca)
```

## (Q2) Outlier Detection with Unsupervised KNN 
### Choosing the Threshold Value of KNN Score
```{r}
# Calculate KNN scores
knn.distances <- get.knn(wbc.pca, k = 5)$nn.dist
knn.scores <- rowMeans(knn.distances)

# Compare thresholds
thresholds <- c(0.90, 0.95, 0.99)
results <- lapply(thresholds, function(p) {
  threshold <- quantile(knn.scores, p)
  wbc.pca$outlier.knn <- ifelse(knn.scores > threshold, 1, 0)
  conf_matrix <- confusionMatrix(factor(wbc.pca$outlier.knn), factor(wbc.raw$y), positive = "1")
  return(c(p, conf_matrix$byClass["Sensitivity"], conf_matrix$byClass["Pos Pred Value"]))
})

# Display results
threshold_results <- do.call(rbind, results)
colnames(threshold_results) <- c("Percentile", "Sensitivity", "Precision")
print(threshold_results)
```
#### Rationale for Choosing the Threshold Value of KNN Score
In cancer detection, we prioritize **reducing false negatives (missing actual cancer cases)**, so a lower threshold is more applicable. Here, we chose the 90th percentile of the KNN scores as the threshold, identifying the top 10% of points as outliers. The 0.90 percentile threshold is the best choice because it achieves the highest Sensitivity (0.7143), aligning with the objective of reducing False Negatives. Although Precision is lower, the focus is not on minimizing False Positives but on ensuring cancer cases are flagged.

### Apply KNN Outlier Detection
```{r}
# Assign outlier labels based on threshold
threshold <- quantile(knn.scores, 0.90) # top 10% as outliers
wbc.pca$outlier.knn <- ifelse(knn.scores > threshold, 1, 0)

# Visualize KNN outliers
ggplot(wbc.pca, aes(x = PC1, y = PC2, color = as.factor(outlier.knn))) +
  geom_point() +
  scale_color_manual(values = c("0" = "darkblue", "1" = "violet")) +
  labs(title = "KNN Outlier Detection", color = "Outlier")
```

#### Insight from KNN Outlier Dectection Visual
The dark blue points (Outlier = 0) represent data points that are considered within the "normal" range, meaning their KNN scores fall below the threshold set for outlier detection. The pink points (Outlier = 1) indicate the outliers, which are data points with KNN scores above the defined threshold (10%). However, the separation between outliers and normal points is not perfectly clear-cut. WE need to perform a confusion matrix analysis to evaluate the effectiveness of the outlier detection in identifying actual cancer cases.


## (Q3) Clustering with K-Means
### Determine Optimal Clusters
```{r}
# Elbow method for optimal clusters
fviz_nbclust(wbc.pca, kmeans, method = "wss")
```

```{r}
# Silhouette
fviz_nbclust(wbc.pca, kmeans, method = "silhouette")
```

```{r}
# Gap Stat
fviz_nbclust(wbc.pca, kmeans, method = "gap_stat")
```
### Selecting Optimal Number of Clusters
The elbow method using WSS (Within-Cluster Sum of Squares) pinpoints the point where the decrease in WSS slows significantly as more clusters are added. A higher WSS reflects greater variability within clusters. At **k = 5**, the reduction in WSS levels off, suggesting that adding additional clusters offers minimal improvement to the clustering results. Therefore, we're picking the optimal number of cluster as 5.

### Apply K-Means
```{r}
# Apply K-Means clustering
set.seed(12345)
wbc.kmeans.model <- kmeans(wbc.pca, centers = 5, nstart = 25)

# Assign clusters
wbc.pca$kmeans.cluster <- wbc.kmeans.model$cluster

# Visualize clusters
fviz_cluster(wbc.kmeans.model, data = wbc.pca)
```

#### Insight from K-Means Clustering Visual
This K-means cluster visualization effectively highlights how the data points have been grouped into five distinct clusters based on their similarities. Each cluster is represented with a unique color and shape, making it easier to identify the spatial boundaries and relationships between them.


## KNN and K-Means Evaluation
Using a confusion matrix to evaluate K-Means and KNN models provides a structured way to measure their effectiveness in identifying cancer cases.

- Sensitivity Focus: The confusion matrix directly measures sensitivity, which is essential for medical applications where missing cancer cases can have severe consequences.

- Precision Insight: While False Positives (low precision) may increase patient anxiety or operational costs, they are less critical than missing true cancer cases. The confusion matrix highlights this trade-off.

```{r}
# Add y column (outcome) Back to wbc_pca to perform confusion matrix
wbc.pca$Outcome <- wbc.raw$y
str(wbc.pca) 
str(wbc.raw)
```

### KNN Confusion Matrix
```{r}
conf.matrix.knn <- confusionMatrix(
  factor(wbc.pca$outlier.knn),  # Predicted outliers
  factor(wbc.pca$Outcome),     # Actual cancer labels
  positive = "1"               # Focus on cancer (1) as the positive class
)

# Print the confusion matrix
print(conf.matrix.knn)
```

#### Insights from KNN Confusion Matrix
- Sensitivity (71.43%): This indicates that the model correctly identified 71.43% of actual cancer cases. While this is a decent detection rate, there is room for improvement, especially since minimizing False Negatives (missed cancer cases) is a key priority.

- Specificity (93.56%): The model correctly identified 93.56% of non-cancer cases as such, showing strong performance in reducing False Positives.

This analysis suggests that the KNN model can provide value as a supplementary tool in cancer detection but may requires further optimization before clinical implementation.

### Evaluate K-Means
```{r}
# 1. Compute cancer proportion for KMeans clusters
kmeans.characteristics <- aggregate(wbc.pca$Outcome, by = list(Cluster = wbc.pca$kmeans.cluster), FUN = mean)

# Rename columns for clarity
colnames(kmeans.characteristics) <- c("Cluster", "Cancer_Proportion")

# Display cancer proportion
print(kmeans.characteristics)
```
#### Selecting Cancerous Clusters
Clusters 1 and 3 demonstrate distinct cancer-related characteristics based on their "Cancer_Proportion" values:

**Cluster 1**: With a cancer proportion of approximately 0.1379, this cluster likely contains a mix of cancerous and non-cancerous cases. While cancer-related data is present, it is not the dominant pattern, suggesting the cluster captures subtle overlaps or borderline cases.

**Cluster 3**: A cancer proportion of 1.0 indicates that this cluster exclusively consists of cancerous cases. This makes Cluster 3 a strong indicator of cancer-related data and highlights its potential utility in identifying clear-cut cancer diagnoses.

These insights suggest that while Cluster 3 is highly specific to cancer cases, Cluster 1 may represent patients with mixed or ambiguous health indicators, offering opportunities to refine detection in borderline cases.

### Applying Confusion Matrix
```{r}
# 2. Assign predictions based on cancerous clusters 
cancerous.clusters.kmeans <- c(1, 3)  
wbc.raw$kmeans.prediction <- ifelse(wbc.pca$kmeans.cluster %in% cancerous.clusters.kmeans, 1, 0)

# Ensure predictions and true labels are factors
wbc.raw$kmeans.prediction <- as.factor(wbc.raw$kmeans.prediction)
wbc.raw$y <- as.factor(wbc.raw$y)

# 3. Compute confusion matrix for KMeans
conf.matrix.kmeans <- confusionMatrix(wbc.raw$kmeans.prediction, wbc.raw$y, positive = "1")

# Display the confusion matrix
print(conf.matrix.kmeans)
```
#### Insights from K-Means Confusion Matrix
- Sensitivity (0.90476): The model is highly effective at identifying true positives (cancer cases). This aligns with the objective of minimizing false negatives, as missing cancer cases is critical.

- Specificity (0.78992): The model correctly identifies approximately 79.99% of non-cancer cases, though there is room for improvement to reduce false positives.

Overall, the model performs exceptionally well in sensitivity, aligning with the goal of minimizing missed cancer cases. However, its practical application would require addressing the high false positive rate to ensure efficient use of medical resources.

## Conclusion
In this analysis, unsupervised learning methods, specifically K-Means clustering and KNN-based outlier detection, were evaluated for their effectiveness in identifying cancer cases from patient health data. While these methods offer unique strengths, their limitations underscore the need for careful implementation and integration into clinical workflows. The focus throughout this analysis has been on **minimizing False Negatives**—ensuring that no cancer cases are missed—while also acknowledging the impact of False Positives, which can result in unnecessary testing and patient anxiety.

### Effectiveness of Methods:
- **K-Means Clustering:** The K-Means model demonstrated **strong sensitivity**, effectively identifying a high proportion of true cancer cases. This aligns well with the primary objective of minimizing false negatives, ensuring that as few cancer cases as possible are missed. However, the model suffered from low precision, indicating a tendency to overpredict cancer, which could lead to false alarms and unnecessary follow-up procedures.

- **KNN Outlier Detection:** KNN **successfully identified outliers** that correspond to cancer cases, but its performance was highly dependent on the choice of threshold. Sensitivity decreased as thresholds became stricter, and while precision improved, it came at the cost of missing more cancer cases. This trade-off requires careful consideration when applying this method in a practical healthcare setting.

**Overall, unsupervised learning methods like K-Means and KNN could serve as supplementary tools in cancer detection.** By flagging potential cancer cases, they could assist medical professionals in prioritizing patients for further evaluation. The ability to process unlabeled data is a key advantage, making these methods applicable even in scenarios where labeled datasets are limited or unavailable.

### Benefits and Risks of Unsupervised Learning:
The scalability of these models is a significant advantage. They can process large datasets efficiently, making them suitable for hospitals managing high patient volumes. Additionally, the high sensitivity of these models supports early detection, potentially improving patient outcomes by enabling timely interventions. Furthermore, these models can optimize resource allocation by prioritizing high-risk cases, reducing strain on diagnostic facilities and lowering overall healthcare costs.

Despite their potential, implementing these models in a clinical setting poses several challenges. The interpretability of these models also presents a challenge. Unsupervised methods are less transparent compared to traditional approaches, which could lead to skepticism among clinicians and patients. Ethical considerations, including the potential for model bias and accountability for errors, must also be addressed to ensure responsible implementation.

### Integrated Diagnosis Process
The proposed diagnosis process leverages unsupervised learning models, such as K-Means and KNN, as an initial screening layer. These models analyze patient data to identify anomalies or assign patients to high-risk clusters based on deviations from normal health metrics. Flagged cases are then prioritized for comprehensive diagnostic testing by healthcare professionals, ensuring that the models act as a complementary tool rather than a replacement for traditional methods. Continuous refinement of the models through feedback from confirmed diagnoses will enhance their sensitivity and precision over time, making them more aligned with clinical requirements.

### Final Thoughts
Unsupervised learning methods like K-Means and KNN show significant potential as supplementary tools for cancer detection, particularly in their ability to process large datasets and identify patterns. While False Positives may result in additional diagnostic follow-ups, this is less critical than minimizing False Negatives, which remains the primary focus to ensure no cancer cases are overlooked. These models should be integrated into a broader diagnostic system that includes human expertise for validation, addressing challenges such as interpretability and ethical concerns. With future improvements in precision, threshold optimization, and transparency, unsupervised learning can play a valuable role in improving efficiency, resource allocation, and patient outcomes in cancer detection workflows.
